{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import time\n",
    "%matplotlib notebook\n",
    "import seaborn as sns\n",
    "from scipy.special import expit as logit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.special import expit as sigmoid # is more stable in case of overflows\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, \\\n",
    "recall_score, precision_score, accuracy_score, confusion_matrix, classification_report\n",
    "import math\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_cleaned = pd.read_csv('/data/ortho/AllPatients.csv',  sep= ';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# bereken symmetrie\n",
    "df_cleaned['clavicula_x_dif'] = np.absolute(df_cleaned['clavicula_l_x'] - df_cleaned['clavicula_r_x'])\n",
    "df_cleaned['clavicula_y_dif'] = np.absolute(df_cleaned['clavicula_l_y'] - df_cleaned['clavicula_r_y'])\n",
    "df_cleaned['clavicula_z_dif'] = np.absolute(df_cleaned['clavicula_l_z'] - df_cleaned['clavicula_r_z'])\n",
    "\n",
    "df_cleaned['scapula_x_dif'] = np.absolute(df_cleaned['scapula_l_x'] - df_cleaned['scapula_r_x'])\n",
    "df_cleaned['scapula_y_dif'] = np.absolute(df_cleaned['scapula_l_y'] - df_cleaned['scapula_r_y'])\n",
    "df_cleaned['scapula_z_dif'] = np.absolute(df_cleaned['scapula_l_z'] - df_cleaned['scapula_r_z'])\n",
    "\n",
    "df_cleaned['humerus_x_dif'] = np.absolute(df_cleaned['humerus_l_x'] - df_cleaned['humerus_r_x'])\n",
    "df_cleaned['humerus_y_dif'] = np.absolute(df_cleaned['humerus_l_y'] - df_cleaned['humerus_r_y'])\n",
    "df_cleaned['humerus_z_dif'] = np.absolute(df_cleaned['humerus_l_z'] - df_cleaned['humerus_r_z'])\n",
    "\n",
    "# hulp array, met alle parameters die voor de classifier gebruikt worden, je kan hier alles in doen wat je wilt\n",
    "param = [ \\\n",
    "          'humerus_l_x', 'humerus_l_y', 'humerus_l_z', 'humerus_r_x', 'humerus_r_y', 'humerus_r_z', \\\n",
    "          'clavicula_l_x', 'clavicula_l_y', 'clavicula_l_z', 'clavicula_r_x', 'clavicula_r_y', 'clavicula_r_z', \\\n",
    "          'scapula_l_x', 'scapula_l_y', 'scapula_l_z', 'scapula_r_x', 'scapula_r_y', 'scapula_r_z'\n",
    "         ]\n",
    "\n",
    "df_cleaned['bias'] = 1\n",
    "\n",
    "# split oorsprong kolom in onderdelen\n",
    "x,y = df_cleaned['Oorsprong'].str.split(\".\").str #Oordprong word vertaald naar een string en wordt gesplits op de punt\n",
    "df_cleaned['cat'],df_cleaned['pat'],df_cleaned['meting'],df_cleaned['oef'] = x.str.split(\"_\").str #4 categorieen gemaakt obv file name\n",
    "df_cleaned['cat'] = [ int(x[3:]) for x in df_cleaned['cat']] #voor elk 3+ element in de kolom wordt vertaald naar een int\n",
    "df_cleaned['meting'] = [ int(x[6:]) for x in df_cleaned['meting']] \n",
    "df_cleaned['oef'] = [ int(x[3:]) for x in df_cleaned['oef']] \n",
    "df_cleaned['pat'] = [ int(x[3:]) for x in df_cleaned['pat']] \n",
    "#na deze regels te hebben uitgevoerd zijn er nieuwe categorieen met ints.\n",
    "\n",
    "df_cleaned['pat'] = df_cleaned['cat']*1000+df_cleaned['pat'] #geef elke patient een uniek nummer\n",
    "\n",
    "#maak boolean kolom per categorie\n",
    "df_cleaned['c4'] = ['Cat4' in vincent for vincent in df_cleaned['Oorsprong']]\n",
    "df_cleaned['c3'] = ['Cat3' in vincent for vincent in df_cleaned['Oorsprong']]\n",
    "df_cleaned['c2'] = ['Cat2' in vincent for vincent in df_cleaned['Oorsprong']]\n",
    "df_cleaned['c1'] = ['Cat1' in vincent for vincent in df_cleaned['Oorsprong']]\n",
    "\n",
    "df_cleaned['y'] = [('Cat1' or 'Cat2') in vincent for vincent in df_cleaned['Oorsprong']]\n",
    "\n",
    "\n",
    "# df_cleaned = df_cleaned[~df_cleaned.c3]\n",
    "# df_cleaned = df_cleaned[~df_cleaned.c2]\n",
    "\n",
    "\n",
    "\n",
    "Xcolumns = ['bias']\n",
    "Xcolumns.extend(param)\n",
    "\n",
    "X = df_cleaned[Xcolumns]\n",
    "y = df_cleaned['cat']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137152 34289\n",
      "132496 38945\n"
     ]
    }
   ],
   "source": [
    "def SplitData(df, xcol, ycol, percentage):\n",
    "    allIndex = np.unique(df['pat'].tolist()) # Get all unique patients id's\n",
    "    random.seed(2) # Set random seeed so the answer is the same\n",
    "    \n",
    "    PercentageIndex = []\n",
    "    for i in np.unique(np.floor(allIndex / 1000)): # Cycle through each categorie (only cycles through the ones that are present)\n",
    "        CatPatients = allIndex[allIndex<((i+1)*1000)] # Filters out patients who are bigger then our max\n",
    "        CatPatients = CatPatients[CatPatients>=((i)*1000)] # Filters out patients that are smaller\n",
    "        \n",
    "        AmountItems = len(CatPatients)\n",
    "        AmountRandom = math.floor(AmountItems*percentage)\n",
    "        PercentageIndex.extend(random.sample(list(CatPatients), AmountRandom))        \n",
    "        \n",
    "    AmountItems = len(allIndex)\n",
    "    AmountRandom = math.floor(AmountItems*percentage)\n",
    "    \n",
    "    PercentageIndex = random.sample(list(allIndex), AmountRandom)\n",
    "    \n",
    "    Percentagedf = df[xcol][df['pat'].isin(PercentageIndex)]\n",
    "    Percentagey = df[ycol][df['pat'].isin(PercentageIndex)]\n",
    "    \n",
    "    Testdf = df[xcol][~df['pat'].isin(PercentageIndex)]\n",
    "    Testy = df[ycol][~df['pat'].isin(PercentageIndex)]\n",
    "    \n",
    "    return (Percentagedf, Testdf, Percentagey, Testy)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)\n",
    "# print(len(X_train), len(X_test))\n",
    "X_train, X_test, y_train, y_test = SplitData(df_cleaned, Xcolumns, 'cat', 0.8)\n",
    "print(len(X_train), len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137152 34289\n",
      "Iteration 1, loss = 2.88422291\n",
      "Iteration 2, loss = 0.94235803\n",
      "Iteration 3, loss = 0.82471796\n",
      "Iteration 4, loss = 0.77921663\n",
      "Iteration 5, loss = 0.74538476\n",
      "Iteration 6, loss = 0.71410457\n",
      "Iteration 7, loss = 0.68205885\n",
      "Iteration 8, loss = 0.65636604\n",
      "Iteration 9, loss = 0.63609431\n",
      "Iteration 10, loss = 0.61783854\n",
      "Iteration 11, loss = 0.59213686\n",
      "Iteration 12, loss = 0.57161980\n",
      "Iteration 13, loss = 0.55437023\n",
      "Iteration 14, loss = 0.54315736\n",
      "Iteration 15, loss = 0.53468786\n",
      "Iteration 16, loss = 0.52677639\n",
      "Iteration 17, loss = 0.52291922\n",
      "Iteration 18, loss = 0.51796221\n",
      "Iteration 19, loss = 0.51334866\n",
      "Iteration 20, loss = 0.51105407\n",
      "Iteration 21, loss = 0.50745602\n",
      "Iteration 22, loss = 0.50406932\n",
      "Iteration 23, loss = 0.50047064\n",
      "Iteration 24, loss = 0.49832629\n",
      "Iteration 25, loss = 0.49507702\n",
      "Iteration 26, loss = 0.49367290\n",
      "Iteration 27, loss = 0.49369355\n",
      "Iteration 28, loss = 0.49034325\n",
      "Iteration 29, loss = 0.48896736\n",
      "Iteration 30, loss = 0.48192517\n",
      "Iteration 31, loss = 0.47759103\n",
      "Iteration 32, loss = 0.47340607\n",
      "Iteration 33, loss = 0.47074346\n",
      "Iteration 34, loss = 0.46396833\n",
      "Iteration 35, loss = 0.46145038\n",
      "Iteration 36, loss = 0.45590341\n",
      "Iteration 37, loss = 0.45109362\n",
      "Iteration 38, loss = 0.44999143\n",
      "Iteration 39, loss = 0.44818850\n",
      "Iteration 40, loss = 0.44732360\n",
      "Iteration 41, loss = 0.44495888\n",
      "Iteration 42, loss = 0.44510913\n",
      "Iteration 43, loss = 0.44407381\n",
      "Iteration 44, loss = 0.44286892\n",
      "Iteration 45, loss = 0.44216659\n",
      "Iteration 46, loss = 0.44076678\n",
      "Iteration 47, loss = 0.44126321\n",
      "Iteration 48, loss = 0.43993699\n",
      "Iteration 49, loss = 0.43878133\n",
      "Iteration 50, loss = 0.43839350\n",
      "Iteration 51, loss = 0.43719485\n",
      "Iteration 52, loss = 0.43521487\n",
      "Iteration 53, loss = 0.43606925\n",
      "Iteration 54, loss = 0.43330272\n",
      "Iteration 55, loss = 0.43405102\n",
      "Iteration 56, loss = 0.43251642\n",
      "Iteration 57, loss = 0.43270699\n",
      "Iteration 58, loss = 0.43153244\n",
      "Iteration 59, loss = 0.43115546\n",
      "Iteration 60, loss = 0.43100053\n",
      "Iteration 61, loss = 0.42959476\n",
      "Iteration 62, loss = 0.42770691\n",
      "Iteration 63, loss = 0.42773454\n",
      "Iteration 64, loss = 0.42733141\n",
      "Iteration 65, loss = 0.42751282\n",
      "Iteration 66, loss = 0.42730321\n",
      "Iteration 67, loss = 0.42546526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/jupyterhub/anaconda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=18, learning_rate='adaptive',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=21, shuffle=True, solver='adam', tol=1e-05,\n",
       "       validation_fraction=0.1, verbose=10, warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = MLPClassifier(hidden_layer_sizes=(18),solver='adam', random_state=21,tol=0.00001,learning_rate='adaptive',verbose=10)\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.43      0.56     14033\n",
      "           2       0.22      0.56      0.32      4846\n",
      "           3       0.59      0.50      0.54      6622\n",
      "           4       0.59      0.65      0.62      1049\n",
      "\n",
      "   micro avg       0.48      0.48      0.48     26550\n",
      "   macro avg       0.55      0.53      0.51     26550\n",
      "weighted avg       0.63      0.48      0.51     26550\n",
      "\n",
      "         countF                        GroundTruth  percentage\n",
      "Predict       1       2       3      4                        \n",
      "pat                                                           \n",
      "1001      516.0   375.0    52.0    NaN         1.0   54.718982\n",
      "1002       12.0  1007.0   113.0    NaN         1.0    1.060071\n",
      "1003      291.0   587.0    24.0    NaN         1.0   32.261641\n",
      "1006      868.0   333.0     9.0    NaN         1.0   71.735537\n",
      "1007      383.0   843.0   217.0    NaN         1.0   26.541927\n",
      "1010      551.0   503.0   435.0    NaN         1.0   37.004701\n",
      "1011      264.0   951.0    19.0    NaN         1.0   21.393841\n",
      "1014     1069.0   101.0     NaN    NaN         1.0   91.367521\n",
      "1015       88.0  1167.0   231.0    NaN         1.0    5.921938\n",
      "1018      510.0   443.0    44.0   92.0         1.0   46.831956\n",
      "1021      852.0     NaN     NaN    NaN         1.0  100.000000\n",
      "1027      576.0   399.0   108.0    NaN         1.0   53.185596\n",
      "2010       93.0  1478.0   557.0    NaN         2.0   69.454887\n",
      "2030      935.0   660.0   189.0    NaN         2.0   36.995516\n",
      "2035      129.0   575.0   230.0    NaN         2.0   61.563169\n",
      "3013      209.0   151.0   358.0    NaN         3.0   49.860724\n",
      "3016       13.0   462.0   341.0    NaN         3.0   41.789216\n",
      "3021       88.0  1405.0   571.0  249.0         3.0   24.686554\n",
      "3026        7.0   297.0  1164.0  131.0         3.0   72.795497\n",
      "3032       11.0   261.0   904.0    NaN         3.0   76.870748\n",
      "4014        NaN   235.0   137.0  677.0         4.0   64.537655\n"
     ]
    }
   ],
   "source": [
    "def CreatPatientLevel(df, ytrue, ypred, Xtest):\n",
    "    \n",
    "    def CalculatePerc(cat, CountF1, CountF2, CountF3, CountF4):\n",
    "        Count = [CountF1, CountF2, CountF3, CountF4]\n",
    "        cat = int(cat)\n",
    "        perc = 100*Count[cat-1]/np.nansum(Count)\n",
    "        if(math.isnan(perc)):\n",
    "            perc = 0\n",
    "        return perc\n",
    "\n",
    "    \n",
    "    PatientsDf = pd.DataFrame()\n",
    "    PatientsDf['pat'] = df.loc[Xtest.index.values]['pat']\n",
    "    PatientsDf['GroundTruth'] = ytrue\n",
    "    PatientsDf['Predict'] = ypred\n",
    "\n",
    "    # Groupby\n",
    "    PatientsDf = PatientsDf.groupby(['pat','Predict']).size().to_frame('countF').reset_index()\n",
    "    PatientsDf.set_index(['pat', 'Predict'], inplace=True)\n",
    "    PatientsDf = PatientsDf.unstack(-1)\n",
    "    PatientsDf['GroundTruth'] = np.floor(np.array(PatientsDf.index.values) / 1000)\n",
    "\n",
    "    #Percentage\n",
    "    PatientsDf['percentage'] = np.vectorize(CalculatePerc)(PatientsDf['GroundTruth'], PatientsDf['countF', 1],PatientsDf['countF', 2],PatientsDf['countF', 3],PatientsDf['countF', 4])\n",
    "    PatientsDf.sort_values(by=['percentage'],ascending=False)\n",
    "    return PatientsDf\n",
    "\n",
    "y_true = np.array(list(y_test))\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "print(classification_report(y_true, y_pred))\n",
    "\n",
    "print(CreatPatientLevel(df_cleaned, y_true, y_pred, X_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(data=np.array([y_true, y_pred]).transpose()).to_csv('ding.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 ... 3 1 3]\n",
      "[2 2 2 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)\n",
    "print(np.array(list(y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_cleaned[Xcolumns].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with Testset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned_test = pd.read_csv('AllPatients_Testset.csv',  sep= ';')\n",
    "\n",
    "# bereken symmetrie\n",
    "df_cleaned_test['clavicula_x_dif'] = np.absolute(df_cleaned_test['clavicula_l_x'] - df_cleaned_test['clavicula_r_x'])\n",
    "df_cleaned_test['clavicula_y_dif'] = np.absolute(df_cleaned_test['clavicula_l_y'] - df_cleaned_test['clavicula_r_y'])\n",
    "df_cleaned_test['clavicula_z_dif'] = np.absolute(df_cleaned_test['clavicula_l_z'] - df_cleaned_test['clavicula_r_z'])\n",
    "\n",
    "df_cleaned_test['scapula_x_dif'] = np.absolute(df_cleaned_test['scapula_l_x'] - df_cleaned_test['scapula_r_x'])\n",
    "df_cleaned_test['scapula_y_dif'] = np.absolute(df_cleaned_test['scapula_l_y'] - df_cleaned_test['scapula_r_y'])\n",
    "df_cleaned_test['scapula_z_dif'] = np.absolute(df_cleaned_test['scapula_l_z'] - df_cleaned_test['scapula_r_z'])\n",
    "\n",
    "df_cleaned_test['humerus_x_dif'] = np.absolute(df_cleaned_test['humerus_l_x'] - df_cleaned_test['humerus_r_x'])\n",
    "df_cleaned_test['humerus_y_dif'] = np.absolute(df_cleaned_test['humerus_l_y'] - df_cleaned_test['humerus_r_y'])\n",
    "df_cleaned_test['humerus_z_dif'] = np.absolute(df_cleaned_test['humerus_l_z'] - df_cleaned_test['humerus_r_z'])\n",
    "\n",
    "# hulp array, met alle parameters die voor de classifier gebruikt worden, je kan hier alles in doen wat je wilt\n",
    "param_test = [ \\\n",
    "          'humerus_l_x', 'humerus_l_y', 'humerus_l_z', 'humerus_r_x', 'humerus_r_y', 'humerus_r_z', \\\n",
    "          'clavicula_l_x', 'clavicula_l_y', 'clavicula_l_z', 'clavicula_r_x', 'clavicula_r_y', 'clavicula_r_z', \\\n",
    "          'scapula_l_x', 'scapula_l_y', 'scapula_l_z', 'scapula_r_x', 'scapula_r_y', 'scapula_r_z', \\\n",
    "          'clavicula_x_dif','clavicula_y_dif','clavicula_z_dif', \\\n",
    "          'scapula_x_dif','scapula_y_dif','scapula_z_dif', \\\n",
    "          'humerus_x_dif', 'humerus_y_dif', 'humerus_z_dif'\n",
    "         ]\n",
    "\n",
    "df_cleaned_test['bias'] = 1\n",
    "\n",
    "# split oorsprong kolom in onderdelen\n",
    "x,y = df_cleaned_test['Oorsprong'].str.split(\".\").str #Oordprong word vertaald naar een string en wordt gesplits op de punt\n",
    "df_cleaned_test['cat'],df_cleaned_test['pat'],df_cleaned_test['meting'],df_cleaned_test['oef'] = x.str.split(\"_\").str #4 categorieen gemaakt obv file name\n",
    "df_cleaned_test['cat'] = [ int(x[3:]) for x in df_cleaned_test['cat']] #voor elk 3+ element in de kolom wordt vertaald naar een int\n",
    "df_cleaned_test['meting'] = [ int(x[6:]) for x in df_cleaned_test['meting']] \n",
    "df_cleaned_test['oef'] = [ int(x[3:]) for x in df_cleaned_test['oef']] \n",
    "df_cleaned_test['pat'] = [ int(x[3:]) for x in df_cleaned_test['pat']] \n",
    "#na deze regels te hebben uitgevoerd zijn er nieuwe categorieen met ints.\n",
    "\n",
    "df_cleaned_test['pat'] = df_cleaned_test['cat']*1000+df_cleaned_test['pat'] #geef elke patient een uniek nummer\n",
    "\n",
    "#maak boolean kolom per categorie\n",
    "df_cleaned_test['c4'] = ['Cat4' in vincent for vincent in df_cleaned_test['Oorsprong']]\n",
    "df_cleaned_test['c3'] = ['Cat3' in vincent for vincent in df_cleaned_test['Oorsprong']]\n",
    "df_cleaned_test['c2'] = ['Cat2' in vincent for vincent in df_cleaned_test['Oorsprong']]\n",
    "df_cleaned_test['c1'] = ['Cat1' in vincent for vincent in df_cleaned_test['Oorsprong']]\n",
    "\n",
    "df_cleaned_test['y'] = [('Cat1' or 'Cat2') in vincent for vincent in df_cleaned_test['Oorsprong']]\n",
    "\n",
    "\n",
    "# df_cleaned_test = df_cleaned_test[~df_cleaned_test.c3]\n",
    "# df_cleaned_test = df_cleaned_test[~df_cleaned_test.c2]\n",
    "\n",
    "\n",
    "\n",
    "Xcolumns_test = ['bias']\n",
    "Xcolumns_test.extend(param)\n",
    "\n",
    "X_test_test = df_cleaned_test[Xcolumns_test]\n",
    "y_test_test = df_cleaned_test['cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.57      0.67      4529\n",
      "           2       0.46      0.58      0.51      6715\n",
      "           3       0.58      0.59      0.58      7531\n",
      "           4       0.75      0.38      0.50      1076\n",
      "\n",
      "   micro avg       0.57      0.57      0.57     19851\n",
      "   macro avg       0.65      0.53      0.57     19851\n",
      "weighted avg       0.60      0.57      0.57     19851\n",
      "\n",
      "         countF                        GroundTruth percentage\n",
      "Predict       1       2       3      4                       \n",
      "pat                                                          \n",
      "1009       46.0  1110.0   136.0    NaN         1.0   3.560372\n",
      "1025     1456.0   185.0     7.0    NaN         1.0  88.349515\n",
      "1028     1082.0   211.0   296.0    NaN         1.0  68.093140\n",
      "2013       80.0  1334.0  1126.0   25.0         2.0  52.007797\n",
      "2016       32.0   959.0   462.0   15.0         2.0  65.326975\n",
      "2019      119.0  1089.0   562.0    NaN         2.0  61.525424\n",
      "2040       79.0   514.0   293.0   26.0         2.0  56.359649\n",
      "3001       14.0   436.0   976.0   57.0         3.0  65.812542\n",
      "3004       73.0  1183.0   945.0   12.0         3.0  42.702214\n",
      "3019        NaN   447.0   710.0    NaN         3.0  61.365601\n",
      "3023        NaN   165.0   655.0    NaN         3.0  79.878049\n",
      "3036      183.0   536.0  1136.0    3.0         3.0  61.141012\n",
      "4013       55.0   250.0   365.0  406.0         4.0  37.732342\n"
     ]
    }
   ],
   "source": [
    "y_true_test = np.array(list(y_test_test))\n",
    "y_pred_test = lr.predict(X_test_test)\n",
    "\n",
    "print(classification_report(y_true_test, y_pred_test))\n",
    "\n",
    "print(CreatPatientLevel(df_cleaned_test, y_true_test, y_pred_test, X_test_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
